from .base import BaseLLM

class MockLLM(BaseLLM):
    async def generate(self, prompt: str, user_id: str) -> str:
        return (
            f"Hello! I'm Aura.\n\n"
            f"You asked: '{prompt}'\n\n"
            f"This response is generated by Aura's core LLM service. "
            f"The same backend powers Discord, web, WhatsApp, and X integrations."
        )
